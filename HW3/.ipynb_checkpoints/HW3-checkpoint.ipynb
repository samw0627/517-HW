{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## TECHIN 513 - Basic ML\n",
        "\n",
        "**Instructions**\n",
        "\n",
        "Install the required packages (scikit-learn, TensorFlow, Keras, PyTorch, and, pandas) if they are not already installed."
      ],
      "metadata": {
        "id": "JLRJNDGiPU37"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use pip to install the packages\n",
        "!pip install scikit-learn TensorFlow Keras PyTorch pandas numpy\n",
        "\n",
        "# Import necessary packages\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "# import RandomForestClassifier from sklearn\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Task 1: Load the Iris dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Task 2: Split the data into training and testing sets\n",
        "# use train_test_split function to split the data with test_size = 0.2 and random_state = 42\n",
        "\n",
        "# Task 3: Train a Random Forest Classifier on the training data\n",
        "# import RandomForestClassifier from sklearn and fit it with training data\n",
        "\n",
        "# Task 4: Evaluate the classifier on the testing data\n",
        "# use clf.score function to evaluate the classifier on the testing data\n",
        "# print the accuracy of the classifier\n",
        "\n",
        "# Task 5: Load the MNIST dataset\n",
        "# use keras.datasets.mnist.load_data() to load the dataset\n",
        "\n",
        "# Task 6: Preprocess the data\n",
        "# normalize the data by dividing by 255.0\n",
        "# use to_categorical from keras.utils to one-hot encode the labels\n",
        "\n",
        "# Task 7: Define and train a simple neural network using Keras\n",
        "# use Sequential model from keras.models\n",
        "# use Dense layer from keras.layers\n",
        "# use 'adam' as optimizer and 'categorical_crossentropy' as loss function\n",
        "# use model.fit to train the model\n",
        "\n",
        "# Task 8: Evaluate the neural network on the testing data\n",
        "# use model.evaluate to get the test loss and test accuracy\n",
        "\n",
        "# Task 9: Define a simple linear regression model using PyTorch\n",
        "# create a class LinearRegression that inherit from nn.Module\n",
        "# define the constructor and forward function\n",
        "\n",
        "# Task 10: Train the linear regression model on some dummy data and print the weight and bias\n",
        "# create an instance of LinearRegression\n",
        "# use nn.MSELoss as criterion, optim.SGD as optimizer\n",
        "# use model.parameters() as input for optimizer\n",
        "# use optimizer.step() and criterion to update the model weight and bias"
      ],
      "metadata": {
        "id": "JVHNfDPhPjyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bonus"
      ],
      "metadata": {
        "id": "goIaALYXVy1J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bonus Task: Implement a Convolutional Neural Network to classify the CIFAR-10 dataset\n",
        "# use torchvision.datasets.CIFAR10 to load the dataset\n",
        "# create a class CNN that inherit from nn.Module\n",
        "# define the constructor, forward function and the network architecture\n",
        "# use CrossEntropyLoss as criterion, optim.SGD as optimizer\n",
        "# use model.parameters() as input for optimizer\n",
        "# use optimizer.step() and criterion to update the model weight and bias"
      ],
      "metadata": {
        "id": "-ZYu5X7gV1L9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}